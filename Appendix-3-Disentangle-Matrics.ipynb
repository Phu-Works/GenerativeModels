{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From -- https://openreview.net/pdf?id=Sy2fzU9gl. I will use another matrics from https://arxiv.org/pdf/1802.05983.pdf once, I have implemented FactorVAE. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import pickle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata: \n",
      " {b'date': b'April 2017', b'description': b'Disentanglement test Sprites dataset.Procedurally generated 2D shapes, from 6 disentangled latent factors.This dataset uses 6 latents, controlling the color, shape, scale, rotation and position of a sprite. All possible variations of the latents are present. Ordering along dimension 1 is fixed and can be mapped back to the exact latent values that generated that image.We made sure that the pixel outputs are different. No noise added.', b'version': 1, b'latents_names': (b'color', b'shape', b'scale', b'orientation', b'posX', b'posY'), b'latents_possible_values': {b'orientation': array([0.        , 0.16110732, 0.32221463, 0.48332195, 0.64442926,\n",
      "       0.80553658, 0.96664389, 1.12775121, 1.28885852, 1.44996584,\n",
      "       1.61107316, 1.77218047, 1.93328779, 2.0943951 , 2.25550242,\n",
      "       2.41660973, 2.57771705, 2.73882436, 2.89993168, 3.061039  ,\n",
      "       3.22214631, 3.38325363, 3.54436094, 3.70546826, 3.86657557,\n",
      "       4.02768289, 4.1887902 , 4.34989752, 4.51100484, 4.67211215,\n",
      "       4.83321947, 4.99432678, 5.1554341 , 5.31654141, 5.47764873,\n",
      "       5.63875604, 5.79986336, 5.96097068, 6.12207799, 6.28318531]), b'posX': array([0.        , 0.03225806, 0.06451613, 0.09677419, 0.12903226,\n",
      "       0.16129032, 0.19354839, 0.22580645, 0.25806452, 0.29032258,\n",
      "       0.32258065, 0.35483871, 0.38709677, 0.41935484, 0.4516129 ,\n",
      "       0.48387097, 0.51612903, 0.5483871 , 0.58064516, 0.61290323,\n",
      "       0.64516129, 0.67741935, 0.70967742, 0.74193548, 0.77419355,\n",
      "       0.80645161, 0.83870968, 0.87096774, 0.90322581, 0.93548387,\n",
      "       0.96774194, 1.        ]), b'posY': array([0.        , 0.03225806, 0.06451613, 0.09677419, 0.12903226,\n",
      "       0.16129032, 0.19354839, 0.22580645, 0.25806452, 0.29032258,\n",
      "       0.32258065, 0.35483871, 0.38709677, 0.41935484, 0.4516129 ,\n",
      "       0.48387097, 0.51612903, 0.5483871 , 0.58064516, 0.61290323,\n",
      "       0.64516129, 0.67741935, 0.70967742, 0.74193548, 0.77419355,\n",
      "       0.80645161, 0.83870968, 0.87096774, 0.90322581, 0.93548387,\n",
      "       0.96774194, 1.        ]), b'scale': array([0.5, 0.6, 0.7, 0.8, 0.9, 1. ]), b'shape': array([1., 2., 3.]), b'color': array([1.])}, b'latents_sizes': array([ 1,  3,  6, 40, 32, 32]), b'author': b'lmatthey@google.com', b'title': b'dSprites dataset'}\n"
     ]
    }
   ],
   "source": [
    "## Code from Deepmind's Github\n",
    "load_data = np.load(\"dsprites-dataset/dsprites_ndarray_co1sh3sc6or40x32y32_64x64.npz\", encoding='bytes')\n",
    "imgs = load_data['imgs']\n",
    "latents_values = load_data['latents_values']\n",
    "latents_classes = load_data['latents_classes']\n",
    "metadata = load_data['metadata'][()]\n",
    "\n",
    "print('Metadata: \\n', metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = 'save/VAESprite'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAESprite(tf.keras.Model):\n",
    "    \"\"\"Same Architecture\"\"\"\n",
    "    def __init__(self, latent_dim):\n",
    "        super().__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        \n",
    "        self.encoder = tf.keras.Sequential([\n",
    "            tf.keras.layers.InputLayer(input_shape=(64, 64, 1)),\n",
    "            tf.keras.layers.Conv2D(filters=32, kernel_size=4, strides=(2, 2), activation=tf.nn.elu),\n",
    "            tf.keras.layers.Conv2D(filters=32, kernel_size=4, strides=(2, 2), activation=tf.nn.elu),\n",
    "            tf.keras.layers.Conv2D(filters=64, kernel_size=4, strides=(2, 2), activation=tf.nn.elu),\n",
    "            tf.keras.layers.Conv2D(filters=64, kernel_size=4, strides=(2, 2), activation=tf.nn.elu),\n",
    "            tf.keras.layers.Flatten(),\n",
    "            tf.keras.layers.Dense(latent_dim + latent_dim),\n",
    "        ])\n",
    "        \n",
    "        self.decoder = tf.keras.Sequential([\n",
    "            tf.keras.layers.InputLayer(input_shape=(latent_dim,)),\n",
    "            tf.keras.layers.Dense(units=2*2*64, activation=tf.nn.relu),\n",
    "            tf.keras.layers.Reshape(target_shape=(2, 2, 64)),\n",
    "            tf.keras.layers.Conv2DTranspose(filters=64, kernel_size=4, strides=(2, 2), padding=\"SAME\", activation=tf.nn.elu),\n",
    "            tf.keras.layers.Conv2DTranspose(filters=64, kernel_size=4, strides=(2, 2), padding=\"SAME\", activation=tf.nn.elu),\n",
    "            tf.keras.layers.Conv2DTranspose(filters=32, kernel_size=4, strides=(4, 4), padding=\"SAME\", activation=tf.nn.elu),\n",
    "            tf.keras.layers.Conv2DTranspose(filters=32, kernel_size=2, strides=(2, 2), padding=\"SAME\", activation=tf.nn.elu),\n",
    "            tf.keras.layers.Conv2DTranspose(filters=1, kernel_size=1, strides=(1, 1), padding=\"SAME\"),\n",
    "        ])\n",
    "        \n",
    "    def sample(self):\n",
    "        latent = tf.random_normal(shape=(1, self.latent_dim))\n",
    "        return latent, tf.nn.sigmoid(self.decoder(latent))\n",
    "    \n",
    "    def call(self, img, is_sigmoid=False):\n",
    "        \"\"\"Reuse the code from the Google Example\"\"\"\n",
    "        mean, log_var = tf.split(self.encoder(img), num_or_size_splits=2, axis=1)\n",
    "        \n",
    "        normal = tf.random_normal(shape=mean.shape)\n",
    "        latent = normal * tf.exp(log_var * .5) + mean\n",
    "        \n",
    "        out = self.decoder(latent)\n",
    "        if is_sigmoid:\n",
    "            out = tf.nn.sigmoid(out)\n",
    "        return latent, out, mean, log_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = VAESprite(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.checkpointable.util.CheckpointLoadStatus at 0x11088fba8>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate=5e-5)\n",
    "saver = tf.train.Checkpoint(optimizer=optimizer,\n",
    "                            model=vae,\n",
    "                            optimizer_step=tf.train.get_or_create_global_step())\n",
    "saver.restore(tf.train.latest_checkpoint(save_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "latents_sizes = metadata[b'latents_sizes']\n",
    "latents_bases = np.concatenate((latents_sizes[::-1].cumprod()[::-1][1:],\n",
    "                                np.array([1,])))\n",
    "\n",
    "def latent_to_index(latents):\n",
    "    return np.dot(latents, latents_bases).astype(int)\n",
    "\n",
    "def sample_latent(size=1):\n",
    "    samples = np.zeros((size, latents_sizes.size))\n",
    "    for lat_i, lat_size in enumerate(latents_sizes):\n",
    "        samples[:, lat_i] = np.random.randint(lat_size, size=size)\n",
    "\n",
    "    return samples\n",
    "\n",
    "def show_images_grid(imgs_, num_images=25):\n",
    "    ncols = 1\n",
    "    nrows = num_images\n",
    "    _, axes = plt.subplots(ncols, nrows, figsize=(nrows * 2, ncols * 2))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for ax_i, ax in enumerate(axes):\n",
    "        if ax_i < num_images:\n",
    "            ax.imshow(imgs_[ax_i], cmap='Greys_r',  interpolation='nearest')\n",
    "            ax.set_xticks([])\n",
    "            ax.set_yticks([])\n",
    "        else:\n",
    "            ax.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_training_data = 10000\n",
    "number_testing_data = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_training_data = []\n",
    "all_testing_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data(attr, number_data):\n",
    "    training_data = []\n",
    "    for i in range(number_data):\n",
    "        if i%1000 == 0:\n",
    "            print(f\"At {i}\")\n",
    "        latents_sampled = sample_latent(size=70)\n",
    "\n",
    "        latents_sampled[:, attr] = 1\n",
    "        indices_sampled = latent_to_index(latents_sampled)\n",
    "        imgs_sampled = imgs[indices_sampled]\n",
    "        imgs_sampled_tensor = tf.expand_dims(tf.convert_to_tensor(imgs_sampled, tf.float32), axis=-1)\n",
    "\n",
    "        latent, _, _, _ = vae(imgs_sampled_tensor)\n",
    "        left, right = tf.split(latent, 2)\n",
    "\n",
    "        final_latent = tf.reduce_mean(tf.abs(left - right), axis=0)\n",
    "        training_data.append((final_latent.numpy(), attr))\n",
    "        \n",
    "    return training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At 0\n",
      "--------\n",
      "At 0\n",
      "--------\n",
      "At 0\n",
      "--------\n",
      "At 0\n",
      "--------\n",
      "At 0\n",
      "--------\n"
     ]
    }
   ],
   "source": [
    "for attr in range(1, 6):\n",
    "    all_testing_data += create_data(attr, number_testing_data)\n",
    "    print(\"--------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_set, testing_label = list(zip(*all_testing_data))\n",
    "testing_set = np.stack(list(testing_set))\n",
    "testing_label = list(testing_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('linear_classifier_train/VAE_Testing_Linear.npy', testing_set)\n",
    "pickle.dump(testing_label, open('linear_classifier_train/VAE_Testing_Linear_label.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At 0\n",
      "At 1000\n",
      "At 2000\n",
      "At 3000\n",
      "At 4000\n",
      "At 5000\n",
      "At 6000\n",
      "At 7000\n",
      "At 8000\n",
      "At 9000\n",
      "--------\n",
      "At 0\n",
      "At 1000\n",
      "At 2000\n",
      "At 3000\n",
      "At 4000\n",
      "At 5000\n",
      "At 6000\n",
      "At 7000\n",
      "At 8000\n",
      "At 9000\n",
      "--------\n",
      "At 0\n",
      "At 1000\n",
      "At 2000\n",
      "At 3000\n",
      "At 4000\n",
      "At 5000\n",
      "At 6000\n",
      "At 7000\n",
      "At 8000\n",
      "At 9000\n",
      "--------\n",
      "At 0\n",
      "At 1000\n",
      "At 2000\n",
      "At 3000\n",
      "At 4000\n",
      "At 5000\n",
      "At 6000\n",
      "At 7000\n",
      "At 8000\n",
      "At 9000\n",
      "--------\n",
      "At 0\n",
      "At 1000\n",
      "At 2000\n",
      "At 3000\n",
      "At 4000\n",
      "At 5000\n",
      "At 6000\n",
      "At 7000\n",
      "At 8000\n",
      "At 9000\n",
      "--------\n"
     ]
    }
   ],
   "source": [
    "for attr in range(1, 6):\n",
    "    all_training_data += create_data(attr, number_training_data)\n",
    "    print(\"--------\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set, training_label = list(zip(*all_training_data))\n",
    "training_set = np.stack(list(training_set))\n",
    "training_label = list(training_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('linear_classifier_train/VAE_Training_Linear.npy', training_set)\n",
    "pickle.dump(training_label, open('linear_classifier_train/VAE_Training_Linear_label.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 10)\n",
      "(5000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(np.load(\"linear_classifier_train/VAE_Training_Linear.npy\").shape)\n",
    "print(np.load(\"linear_classifier_train/VAE_Testing_Linear.npy\").shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n",
      "5000\n"
     ]
    }
   ],
   "source": [
    "print(len(pickle.load(open('linear_classifier_train/VAE_Training_Linear_label.pkl', 'rb'))))\n",
    "print(len(pickle.load(open('linear_classifier_train/VAE_Testing_Linear_label.pkl', 'rb'))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
