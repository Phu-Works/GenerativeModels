{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import itertools\n",
    "import os\n",
    "\n",
    "experiment_name = \"VAEMultipleShapesNoColor\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = np.load('dsprites-dataset/dsprites_multiple_shapes_no_color.npz.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images_grid(imgs_, num_images=25):\n",
    "    ncols = int(np.ceil(num_images**0.5))\n",
    "    nrows = int(np.ceil(num_images / ncols))\n",
    "    _, axes = plt.subplots(ncols, nrows, figsize=(nrows * 3, ncols * 3))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for ax_i, ax in enumerate(axes):\n",
    "        if ax_i < num_images:\n",
    "            ax.imshow(imgs_[ax_i], cmap='Greys_r',  interpolation='nearest')\n",
    "            ax.set_xticks([])\n",
    "            ax.set_yticks([])\n",
    "        else:\n",
    "            ax.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1829b55278>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_images_grid(np.squeeze(dataset), 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2497500, 64, 64, 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_BUF = 100000\n",
    "BATCH_SIZE = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices(dataset[:100000]).shuffle(TRAIN_BUF).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAESprite(tf.keras.Model):\n",
    "    \"\"\"Same Architecture\"\"\"\n",
    "    def __init__(self, latent_dim, num_object):\n",
    "        super().__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.num_object = num_object\n",
    "        \n",
    "        self.encoder1 = tf.keras.Sequential([\n",
    "            tf.keras.layers.InputLayer(input_shape=(64, 64, 1)),\n",
    "            tf.keras.layers.Conv2D(filters=32, kernel_size=4, strides=(2, 2), activation=tf.nn.elu),\n",
    "            tf.keras.layers.Conv2D(filters=32, kernel_size=4, strides=(2, 2), activation=tf.nn.elu),\n",
    "        ])\n",
    "        \n",
    "        self.encoder2 = tf.keras.Sequential([       \n",
    "            tf.keras.layers.Conv2D(filters=64, kernel_size=4, strides=(2, 2), activation=tf.nn.elu),\n",
    "            tf.keras.layers.Conv2D(filters=24, kernel_size=2, strides=(1, 1), activation=tf.nn.elu),\n",
    "        ])\n",
    "        \n",
    "        self.decoder = tf.keras.Sequential([\n",
    "            tf.keras.layers.InputLayer(input_shape=(latent_dim,)),\n",
    "            tf.keras.layers.Dense(units=2*2*64, activation=tf.nn.relu),\n",
    "            tf.keras.layers.Reshape(target_shape=(2, 2, 64)),\n",
    "            tf.keras.layers.Conv2DTranspose(filters=64, kernel_size=4, strides=(2, 2), padding=\"SAME\", activation=tf.nn.elu),\n",
    "            tf.keras.layers.Conv2DTranspose(filters=64, kernel_size=4, strides=(2, 2), padding=\"SAME\", activation=tf.nn.elu),\n",
    "            tf.keras.layers.Conv2DTranspose(filters=32, kernel_size=4, strides=(4, 4), padding=\"SAME\", activation=tf.nn.elu),\n",
    "            tf.keras.layers.Conv2DTranspose(filters=32, kernel_size=2, strides=(2, 2), padding=\"SAME\", activation=tf.nn.elu),\n",
    "            tf.keras.layers.Conv2DTranspose(filters=1, kernel_size=1, strides=(1, 1), padding=\"SAME\"),\n",
    "        ])\n",
    "    \n",
    "    def call(self, img, is_sigmoid=False):\n",
    "        \"\"\"Reuse the code from the Google Example\"\"\"\n",
    "        encoder1 = self.encoder1(img)\n",
    "        \n",
    "        # Adding x, y coordinate\n",
    "        x = tf.convert_to_tensor([-7, -6, -5, -4, -3, -2, -1, 0, 1, 2, 3, 4, 5, 6])/7\n",
    "        y = tf.convert_to_tensor([-7, -6, -5, -4, -3, -2, -1, 0, 1, 2, 3, 4, 5, 6])/7\n",
    "        \n",
    "        X, Y = tf.meshgrid(x, y)\n",
    "        X, Y = tf.expand_dims(tf.cast(X, tf.float32), -1), tf.expand_dims(tf.cast(Y, tf.float32), -1)\n",
    "        X, Y = tf.expand_dims(tf.cast(X, tf.float32), 0), tf.expand_dims(tf.cast(Y, tf.float32), 0)\n",
    "        \n",
    "        X, Y = tf.tile(X, [encoder1.shape[0], 1, 1, 1]), tf.tile(X, [encoder1.shape[0], 1, 1, 1])\n",
    "        \n",
    "        encoder_pos = tf.concat([encoder1, X, Y], -1)\n",
    "        encoder_final = self.encoder2(encoder_pos)\n",
    "        \n",
    "        encoder_flatten = tf.reshape(encoder_final, (tf.shape(encoder_final)[0], \n",
    "                                                    -1, tf.shape(encoder_final)[-1]))\n",
    "        \n",
    "        mean, log_var = tf.split(encoder_flatten, num_or_size_splits=2, axis=-1)\n",
    "        \n",
    "        # Getting Analytic-KL\n",
    "        kl = 0.5 * tf.reduce_sum(tf.exp(log_var) + mean**2 - 1. - log_var, axis=[-1])\n",
    "        total_kl_value, total_kl_index = tf.math.top_k(kl, k=self.num_object)\n",
    "        \n",
    "        # Getting top 2\n",
    "        top_latent_mean = tf.batch_gather(mean, total_kl_index)\n",
    "        top_latent_log_var = tf.batch_gather(log_var, total_kl_index)\n",
    "        \n",
    "        # Getting latents for each objects \n",
    "        normal = tf.random_normal(shape=top_latent_mean.shape)\n",
    "        each_latent = normal * tf.exp(top_latent_log_var * .5) + top_latent_mean\n",
    "        \n",
    "        # Should I do this ? \n",
    "        latents = tf.reshape(each_latent, (-1, self.latent_dim))\n",
    "        decoded = self.decoder(latents)\n",
    "        \n",
    "        imgs = tf.reshape(decoded, (-1, self.num_object, decoded.shape[1], \n",
    "                                       decoded.shape[2], decoded.shape[3]))\n",
    "        \n",
    "        # Add all images \n",
    "        final_images = tf.reduce_sum(imgs, axis=1)\n",
    "        return each_latent, final_images, top_latent_mean, top_latent_log_var, total_kl_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_size = 12\n",
    "object_number = 2\n",
    "\n",
    "learning_rate = 1e-3\n",
    "\n",
    "def get_learning_rate():\n",
    "    global learning_rate\n",
    "    learning_rate *= 0.9999984649444495\n",
    "    return learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = VAESprite(latent_size, object_number)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=get_learning_rate)\n",
    "\n",
    "global_step = tf.train.get_or_create_global_step()\n",
    "summary_writer = tf.contrib.summary.create_file_writer(f\"tmp/{experiment_name}\")\n",
    "\n",
    "saver = tf.train.Checkpoint(optimizer=optimizer,\n",
    "                            model=vae,\n",
    "                            optimizer_step=tf.train.get_or_create_global_step())\n",
    "\n",
    "save_path = f\"save/{experiment_name}\"\n",
    "if not os.path.exists(save_path):\n",
    "    os.mkdir(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At epoch 0\n",
      "tf.Tensor(2839.8462, shape=(), dtype=float32)\n",
      "tf.Tensor(815.30505, shape=(), dtype=float32)\n",
      "tf.Tensor(718.5691, shape=(), dtype=float32)\n",
      "tf.Tensor(645.3423, shape=(), dtype=float32)\n",
      "tf.Tensor(633.1487, shape=(), dtype=float32)\n",
      "tf.Tensor(593.4791, shape=(), dtype=float32)\n",
      "tf.Tensor(584.58093, shape=(), dtype=float32)\n",
      "tf.Tensor(575.48987, shape=(), dtype=float32)\n",
      "tf.Tensor(546.7737, shape=(), dtype=float32)\n",
      "tf.Tensor(538.746, shape=(), dtype=float32)\n",
      "---------\n",
      "At epoch 1\n",
      "tf.Tensor(518.69476, shape=(), dtype=float32)\n",
      "tf.Tensor(494.92407, shape=(), dtype=float32)\n",
      "tf.Tensor(530.2121, shape=(), dtype=float32)\n",
      "tf.Tensor(488.8722, shape=(), dtype=float32)\n",
      "tf.Tensor(492.69318, shape=(), dtype=float32)\n",
      "tf.Tensor(496.4075, shape=(), dtype=float32)\n",
      "tf.Tensor(463.3467, shape=(), dtype=float32)\n",
      "tf.Tensor(481.63046, shape=(), dtype=float32)\n",
      "tf.Tensor(485.11987, shape=(), dtype=float32)\n",
      "tf.Tensor(473.81015, shape=(), dtype=float32)\n",
      "---------\n",
      "At epoch 2\n",
      "tf.Tensor(451.12878, shape=(), dtype=float32)\n",
      "tf.Tensor(496.0431, shape=(), dtype=float32)\n",
      "tf.Tensor(424.86603, shape=(), dtype=float32)\n",
      "tf.Tensor(445.4547, shape=(), dtype=float32)\n",
      "tf.Tensor(437.5473, shape=(), dtype=float32)\n",
      "tf.Tensor(429.98828, shape=(), dtype=float32)\n",
      "tf.Tensor(435.82184, shape=(), dtype=float32)\n",
      "tf.Tensor(412.28864, shape=(), dtype=float32)\n",
      "tf.Tensor(422.35062, shape=(), dtype=float32)\n",
      "tf.Tensor(430.10757, shape=(), dtype=float32)\n",
      "---------\n",
      "At epoch 3\n",
      "tf.Tensor(409.59656, shape=(), dtype=float32)\n",
      "tf.Tensor(403.32315, shape=(), dtype=float32)\n",
      "tf.Tensor(380.57278, shape=(), dtype=float32)\n",
      "tf.Tensor(412.04315, shape=(), dtype=float32)\n",
      "tf.Tensor(392.77872, shape=(), dtype=float32)\n",
      "tf.Tensor(394.57797, shape=(), dtype=float32)\n",
      "tf.Tensor(381.66824, shape=(), dtype=float32)\n",
      "tf.Tensor(385.48044, shape=(), dtype=float32)\n",
      "tf.Tensor(388.74915, shape=(), dtype=float32)\n",
      "tf.Tensor(390.1057, shape=(), dtype=float32)\n",
      "---------\n",
      "At epoch 4\n",
      "tf.Tensor(374.42825, shape=(), dtype=float32)\n",
      "tf.Tensor(363.07574, shape=(), dtype=float32)\n",
      "tf.Tensor(394.27066, shape=(), dtype=float32)\n",
      "tf.Tensor(359.9625, shape=(), dtype=float32)\n",
      "tf.Tensor(354.53122, shape=(), dtype=float32)\n",
      "tf.Tensor(355.9391, shape=(), dtype=float32)\n",
      "tf.Tensor(364.15872, shape=(), dtype=float32)\n",
      "tf.Tensor(367.87775, shape=(), dtype=float32)\n",
      "tf.Tensor(375.63254, shape=(), dtype=float32)\n",
      "tf.Tensor(374.22107, shape=(), dtype=float32)\n",
      "---------\n",
      "At epoch 5\n",
      "tf.Tensor(370.83585, shape=(), dtype=float32)\n",
      "tf.Tensor(366.7454, shape=(), dtype=float32)\n",
      "tf.Tensor(340.85495, shape=(), dtype=float32)\n",
      "tf.Tensor(335.92764, shape=(), dtype=float32)\n",
      "tf.Tensor(342.7104, shape=(), dtype=float32)\n",
      "tf.Tensor(356.06296, shape=(), dtype=float32)\n",
      "tf.Tensor(345.6367, shape=(), dtype=float32)\n",
      "tf.Tensor(359.70358, shape=(), dtype=float32)\n",
      "tf.Tensor(338.8795, shape=(), dtype=float32)\n",
      "tf.Tensor(347.68118, shape=(), dtype=float32)\n",
      "---------\n",
      "At epoch 6\n",
      "tf.Tensor(341.92856, shape=(), dtype=float32)\n",
      "tf.Tensor(343.0321, shape=(), dtype=float32)\n",
      "tf.Tensor(340.493, shape=(), dtype=float32)\n",
      "tf.Tensor(340.29126, shape=(), dtype=float32)\n",
      "tf.Tensor(332.03738, shape=(), dtype=float32)\n",
      "tf.Tensor(308.21396, shape=(), dtype=float32)\n",
      "tf.Tensor(313.14728, shape=(), dtype=float32)\n",
      "tf.Tensor(335.3346, shape=(), dtype=float32)\n",
      "tf.Tensor(337.11774, shape=(), dtype=float32)\n",
      "tf.Tensor(315.47247, shape=(), dtype=float32)\n",
      "---------\n",
      "At epoch 7\n",
      "tf.Tensor(306.16638, shape=(), dtype=float32)\n",
      "tf.Tensor(317.04993, shape=(), dtype=float32)\n",
      "tf.Tensor(303.55423, shape=(), dtype=float32)\n",
      "tf.Tensor(330.3134, shape=(), dtype=float32)\n",
      "tf.Tensor(330.75278, shape=(), dtype=float32)\n",
      "tf.Tensor(334.0766, shape=(), dtype=float32)\n",
      "tf.Tensor(323.49152, shape=(), dtype=float32)\n",
      "tf.Tensor(327.53546, shape=(), dtype=float32)\n",
      "tf.Tensor(317.65665, shape=(), dtype=float32)\n",
      "tf.Tensor(312.0619, shape=(), dtype=float32)\n",
      "---------\n",
      "At epoch 8\n",
      "tf.Tensor(306.88675, shape=(), dtype=float32)\n",
      "tf.Tensor(302.46606, shape=(), dtype=float32)\n",
      "tf.Tensor(295.4178, shape=(), dtype=float32)\n",
      "tf.Tensor(294.43228, shape=(), dtype=float32)\n",
      "tf.Tensor(305.8326, shape=(), dtype=float32)\n",
      "tf.Tensor(306.1194, shape=(), dtype=float32)\n",
      "tf.Tensor(306.67273, shape=(), dtype=float32)\n",
      "tf.Tensor(316.818, shape=(), dtype=float32)\n",
      "tf.Tensor(310.22855, shape=(), dtype=float32)\n",
      "tf.Tensor(288.82663, shape=(), dtype=float32)\n",
      "---------\n",
      "At epoch 9\n",
      "tf.Tensor(313.08655, shape=(), dtype=float32)\n",
      "tf.Tensor(296.86087, shape=(), dtype=float32)\n",
      "tf.Tensor(283.5663, shape=(), dtype=float32)\n",
      "tf.Tensor(306.53882, shape=(), dtype=float32)\n",
      "tf.Tensor(287.01306, shape=(), dtype=float32)\n",
      "tf.Tensor(297.6493, shape=(), dtype=float32)\n",
      "tf.Tensor(287.48474, shape=(), dtype=float32)\n",
      "tf.Tensor(297.26965, shape=(), dtype=float32)\n",
      "tf.Tensor(318.9251, shape=(), dtype=float32)\n",
      "tf.Tensor(312.95428, shape=(), dtype=float32)\n",
      "---------\n",
      "At epoch 10\n",
      "tf.Tensor(298.27747, shape=(), dtype=float32)\n",
      "tf.Tensor(293.12302, shape=(), dtype=float32)\n",
      "tf.Tensor(310.17184, shape=(), dtype=float32)\n",
      "tf.Tensor(290.86014, shape=(), dtype=float32)\n",
      "tf.Tensor(271.92297, shape=(), dtype=float32)\n",
      "tf.Tensor(300.0415, shape=(), dtype=float32)\n",
      "tf.Tensor(285.4344, shape=(), dtype=float32)\n",
      "tf.Tensor(285.9343, shape=(), dtype=float32)\n",
      "tf.Tensor(287.32977, shape=(), dtype=float32)\n",
      "tf.Tensor(305.16656, shape=(), dtype=float32)\n",
      "---------\n",
      "At epoch 11\n",
      "tf.Tensor(278.12576, shape=(), dtype=float32)\n",
      "tf.Tensor(288.42688, shape=(), dtype=float32)\n",
      "tf.Tensor(301.7671, shape=(), dtype=float32)\n",
      "tf.Tensor(284.91736, shape=(), dtype=float32)\n",
      "tf.Tensor(290.0949, shape=(), dtype=float32)\n",
      "tf.Tensor(294.7903, shape=(), dtype=float32)\n",
      "tf.Tensor(283.5563, shape=(), dtype=float32)\n",
      "tf.Tensor(273.4578, shape=(), dtype=float32)\n",
      "tf.Tensor(268.09262, shape=(), dtype=float32)\n",
      "tf.Tensor(277.2389, shape=(), dtype=float32)\n",
      "---------\n",
      "At epoch 12\n",
      "tf.Tensor(278.2975, shape=(), dtype=float32)\n",
      "tf.Tensor(273.78586, shape=(), dtype=float32)\n",
      "tf.Tensor(281.104, shape=(), dtype=float32)\n",
      "tf.Tensor(293.53214, shape=(), dtype=float32)\n",
      "tf.Tensor(287.25073, shape=(), dtype=float32)\n",
      "tf.Tensor(292.32602, shape=(), dtype=float32)\n",
      "tf.Tensor(272.2847, shape=(), dtype=float32)\n",
      "tf.Tensor(280.234, shape=(), dtype=float32)\n",
      "tf.Tensor(271.48853, shape=(), dtype=float32)\n",
      "tf.Tensor(276.97522, shape=(), dtype=float32)\n",
      "---------\n",
      "At epoch 13\n",
      "tf.Tensor(292.14603, shape=(), dtype=float32)\n",
      "tf.Tensor(272.09296, shape=(), dtype=float32)\n",
      "tf.Tensor(265.16385, shape=(), dtype=float32)\n",
      "tf.Tensor(294.79617, shape=(), dtype=float32)\n",
      "tf.Tensor(282.25385, shape=(), dtype=float32)\n",
      "tf.Tensor(263.2422, shape=(), dtype=float32)\n",
      "tf.Tensor(274.85876, shape=(), dtype=float32)\n",
      "tf.Tensor(294.71014, shape=(), dtype=float32)\n",
      "tf.Tensor(281.2538, shape=(), dtype=float32)\n",
      "tf.Tensor(262.35718, shape=(), dtype=float32)\n",
      "---------\n",
      "At epoch 14\n",
      "tf.Tensor(258.25916, shape=(), dtype=float32)\n",
      "tf.Tensor(273.04257, shape=(), dtype=float32)\n",
      "tf.Tensor(270.9904, shape=(), dtype=float32)\n",
      "tf.Tensor(277.3843, shape=(), dtype=float32)\n",
      "tf.Tensor(253.52153, shape=(), dtype=float32)\n",
      "tf.Tensor(262.50986, shape=(), dtype=float32)\n",
      "tf.Tensor(289.40643, shape=(), dtype=float32)\n",
      "tf.Tensor(243.90381, shape=(), dtype=float32)\n",
      "tf.Tensor(270.65964, shape=(), dtype=float32)\n",
      "tf.Tensor(254.37271, shape=(), dtype=float32)\n",
      "---------\n",
      "At epoch 15\n",
      "tf.Tensor(284.36234, shape=(), dtype=float32)\n",
      "tf.Tensor(277.31784, shape=(), dtype=float32)\n",
      "tf.Tensor(279.30472, shape=(), dtype=float32)\n",
      "tf.Tensor(252.53682, shape=(), dtype=float32)\n",
      "tf.Tensor(259.0558, shape=(), dtype=float32)\n",
      "tf.Tensor(273.7126, shape=(), dtype=float32)\n",
      "tf.Tensor(253.72736, shape=(), dtype=float32)\n",
      "tf.Tensor(270.75214, shape=(), dtype=float32)\n",
      "tf.Tensor(266.83643, shape=(), dtype=float32)\n",
      "tf.Tensor(263.24075, shape=(), dtype=float32)\n",
      "---------\n",
      "At epoch 16\n",
      "tf.Tensor(273.7665, shape=(), dtype=float32)\n",
      "tf.Tensor(284.0697, shape=(), dtype=float32)\n",
      "tf.Tensor(266.46786, shape=(), dtype=float32)\n",
      "tf.Tensor(265.2972, shape=(), dtype=float32)\n",
      "tf.Tensor(266.92148, shape=(), dtype=float32)\n",
      "tf.Tensor(255.80923, shape=(), dtype=float32)\n",
      "tf.Tensor(260.8925, shape=(), dtype=float32)\n",
      "tf.Tensor(262.208, shape=(), dtype=float32)\n",
      "tf.Tensor(254.82918, shape=(), dtype=float32)\n",
      "tf.Tensor(262.98206, shape=(), dtype=float32)\n",
      "---------\n",
      "At epoch 17\n",
      "tf.Tensor(272.6079, shape=(), dtype=float32)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-0879c06fae84>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0mglobal_step\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign_add\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[0;34m(self, target, sources, output_gradients)\u001b[0m\n\u001b[1;32m    899\u001b[0m         \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    900\u001b[0m         \u001b[0mflat_sources\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 901\u001b[0;31m         output_gradients=output_gradients)\n\u001b[0m\u001b[1;32m    902\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_persistent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/eager/imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[0;34m(tape, target, sources, output_gradients)\u001b[0m\n\u001b[1;32m     62\u001b[0m       \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m       \u001b[0msources\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       output_gradients)\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36m_gradient_function\u001b[0;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnum_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/nn_grad.py\u001b[0m in \u001b[0;36m_Conv2DBackpropInputGrad\u001b[0;34m(op, grad)\u001b[0m\n\u001b[1;32m     51\u001b[0m           \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_attr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"padding\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m           \u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_attr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"use_cudnn_on_gpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m           data_format=op.get_attr(\"data_format\")),\n\u001b[0m\u001b[1;32m     54\u001b[0m       nn_ops.conv2d(\n\u001b[1;32m     55\u001b[0m           \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_nn_ops.py\u001b[0m in \u001b[0;36mconv2d_backprop_filter\u001b[0;34m(input, filter_sizes, out_backprop, strides, padding, use_cudnn_on_gpu, data_format, dilations, name)\u001b[0m\n\u001b[1;32m   1110\u001b[0m         \u001b[0mfilter_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_backprop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"strides\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"use_cudnn_on_gpu\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1111\u001b[0m         \u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"padding\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"data_format\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1112\u001b[0;31m         \"dilations\", dilations)\n\u001b[0m\u001b[1;32m   1113\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1114\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for e in range(300):\n",
    "    print(f\"At epoch {e}\")\n",
    "    for i, img in enumerate(train_dataset):\n",
    "        with tf.GradientTape() as tape:\n",
    "            tape.watch(vae.variables)\n",
    "\n",
    "            latent, out, mean, log_var, kl_map = vae(img)\n",
    "            flat_mean = tf.reshape(mean, (-1, latent_size))\n",
    "            flat_log_var = tf.reshape(log_var, (-1, latent_size))\n",
    "\n",
    "            cross_ent = tf.nn.sigmoid_cross_entropy_with_logits(logits=out, labels=img)\n",
    "            logpx_z = -tf.reduce_sum(cross_ent, axis=[1, 2, 3])\n",
    "            kl_loss = 0.5 * tf.reduce_sum(tf.exp(flat_log_var) + flat_mean**2 - 1. - flat_log_var, \n",
    "                                          axis=[1])\n",
    "            kl_loss = tf.reduce_sum(tf.reshape(kl_loss, (-1, object_number)), axis=1)\n",
    "            loss = -tf.reduce_mean(logpx_z - kl_loss)\n",
    "            \n",
    "            if i % 100 == 0:\n",
    "                print(f\"Loss -- {loss} Current Learning Rate {learning_rate}\")\n",
    "                with summary_writer.as_default(), tf.contrib.summary.always_record_summaries():\n",
    "                    tf.contrib.summary.scalar('Loss', loss)\n",
    "                    tf.contrib.summary.image('Before', img)\n",
    "                    tf.contrib.summary.image('Sample', tf.nn.sigmoid(out))\n",
    "                    \n",
    "        \n",
    "        grad = tape.gradient(loss, vae.variables)\n",
    "        global_step.assign_add(1)\n",
    "        optimizer.apply_gradients(zip(grad, vae.variables))\n",
    "        \n",
    "    print(f\"---------\")\n",
    "    saver.save(f\"save/{experiment_name}/{experiment_name}.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a8b95ed30>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_images_grid(tf.squeeze(img).numpy(), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a2d66d9b0>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_images_grid(tf.squeeze(tf.nn.sigmoid(out)).numpy(), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_kl_attention_map(kl_index):\n",
    "    batch_size = kl_index.shape[0]\n",
    "    blank_map = np.zeros((batch_size, 25))\n",
    "    for i in range(batch_size):\n",
    "        blank_map[i][kl_index[i]] = 1\n",
    "    return blank_map.reshape(batch_size, 5, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a2cddfe80>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_images_grid(get_kl_attention_map(kl_map), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
